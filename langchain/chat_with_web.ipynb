{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain langchain_openai PyPDF2 faiss-cpu chromadb google-api-core google-api-python-client google-auth google-auth-httplib2 googleapis-common-protos html2text --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.retrievers.web_research import WebResearchRetriever\n",
    "from langchain_community.utilities import GoogleSearchAPIWrapper\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_openai import AzureChatOpenAI, AzureOpenAIEmbeddings\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "EMBEDDINGS_DEPLOYMENT_NAME = \"text-embedding-ada-002\"\n",
    "EMBEDDINGS_API_VERSION = \"2023-08-01-preview\"\n",
    "\n",
    "DEPLOYMENT_NAME=\"gpt-35-turbo\"\n",
    "MODEL_NAME = \"gpt-35-turbo\"\n",
    "API_VERSION=\"2023-12-01-preview\"\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorstore\n",
    "vectorstore = Chroma(\n",
    "    embedding_function=AzureOpenAIEmbeddings(\n",
    "        azure_deployment=EMBEDDINGS_DEPLOYMENT_NAME,\n",
    "        openai_api_version=EMBEDDINGS_API_VERSION), \n",
    "        persist_directory=\"./chroma_db_oai\"\n",
    ")\n",
    "\n",
    "# LLM\n",
    "llm = AzureChatOpenAI(\n",
    "    azure_deployment=DEPLOYMENT_NAME, \n",
    "    model_name=MODEL_NAME, \n",
    "    openai_api_version=API_VERSION,\n",
    "    temperature=0)\n",
    "\n",
    "# Search\n",
    "search = GoogleSearchAPIWrapper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize\n",
    "web_research_retriever = WebResearchRetriever.from_llm(\n",
    "    vectorstore=vectorstore, llm=llm, search=search\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:langchain.retrievers.web_research:Generating questions for Google Search ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:langchain.retrievers.web_research:Questions for Google Search (raw): {'question': 'How do LLM Powered Autonomous Agents work?', 'text': LineList(lines=['1. What is the functioning principle of LLM Powered Autonomous Agents?\\n', '2. How do LLM Powered Autonomous Agents operate?\\n', '3. Can you explain the working mechanism of LLM Powered Autonomous Agents?'])}\n",
      "INFO:langchain.retrievers.web_research:Questions for Google Search: ['1. What is the functioning principle of LLM Powered Autonomous Agents?\\n', '2. How do LLM Powered Autonomous Agents operate?\\n', '3. Can you explain the working mechanism of LLM Powered Autonomous Agents?']\n",
      "INFO:langchain.retrievers.web_research:Searching for relevant urls...\n",
      "INFO:langchain.retrievers.web_research:Searching for relevant urls...\n",
      "INFO:langchain.retrievers.web_research:Search results: [{'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'link': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'snippet': 'Jun 23, 2023 ... 1. Overview of a LLM-powered autonomous agent system. Component One: Planning#. A complicated task usually involves many steps. An agent needs\\xa0...'}]\n",
      "INFO:langchain.retrievers.web_research:Searching for relevant urls...\n",
      "INFO:langchain.retrievers.web_research:Search results: [{'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'link': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'snippet': 'Jun 23, 2023 ... (1) Task planning: LLM works as the brain and parses the user requests into multiple tasks. There are four attributes associated with each task:\\xa0...'}]\n",
      "INFO:langchain.retrievers.web_research:Searching for relevant urls...\n",
      "INFO:langchain.retrievers.web_research:Search results: [{'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'link': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'snippet': 'Jun 23, 2023 ... Overview of a LLM-powered autonomous agent system. Component One: Planning#. A complicated task usually involves many steps. An agent needs to\\xa0...'}]\n",
      "INFO:langchain.retrievers.web_research:New URLs to load: []\n",
      "INFO:langchain.retrievers.web_research:Grabbing most relevant splits from urls...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': 'How do LLM Powered Autonomous Agents work?',\n",
       " 'answer': \"LLM-powered autonomous agents work by utilizing LLM as the agent's brain, along with several key components such as planning, memory, and tool use. In terms of planning, the agent breaks down large tasks into smaller subgoals and can reflect on past actions to improve future results. The agent also utilizes short-term and long-term memory to learn and retain information. Additionally, the agent can call external APIs for additional information. The design of generative agents combines LLM with memory, planning, and reflection mechanisms to enable agents to behave based on past experience and interact with other agents.\\n\",\n",
       " 'sources': '',\n",
       " 'source_documents': [Document(page_content=\"# Agent System Overview#\\n\\nIn a LLM-powered autonomous agent system, LLM functions as the agent's brain,\\ncomplemented by several key components:\\n\\n  * **Planning**\\n    * Subgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\n    * Reflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n  * **Memory**\\n    * Short-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\n    * Long-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n  * **Tool use**\\n    * The agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\n\\n# Component One: Planning#\\n\\nA complicated task usually involves many steps. An agent needs to know what\\nthey are and plan ahead.\\n\\n## Task Decomposition#\", metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview In a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"}),\n",
       "  Document(page_content='The design of generative agents combines LLM with memory, planning and\\nreflection mechanisms to enable agents to behave conditioned on past\\nexperience, as well as to interact with other agents.', metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview In a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"})]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import logging\n",
    "\n",
    "logging.basicConfig()\n",
    "logging.getLogger(\"langchain.retrievers.web_research\").setLevel(logging.INFO)\n",
    "from langchain.chains import RetrievalQAWithSourcesChain\n",
    "\n",
    "user_input = \"How do LLM Powered Autonomous Agents work?\"\n",
    "qa_chain = RetrievalQAWithSourcesChain.from_chain_type(\n",
    "    llm, retriever=web_research_retriever, return_source_documents=True\n",
    ")\n",
    "\n",
    "qa_chain.invoke({\"question\": user_input})\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
