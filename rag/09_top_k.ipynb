{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top-K Similarity Search \n",
    "Top-K Similarity search type which specifies how you should retrieve documents from your knowledge base. This is type of a retrieval method\n",
    "\n",
    "Top-K Similarity search is the process of pulling \"K\" number of documents from your knowledge base. Its aim is to get you the most similar documents to a query according to your similarity metric.\n",
    "\n",
    "There are two concepts which are important\n",
    "\n",
    "- **Similarity Metric** - This is the equation or metric you'll use to compare the embedding of your query to the embeddings of your corpus of documents. The most common similarity metrics are cosine, dotproduct, and euclidean. The smaller the metric, the more similar two embeddings are expected to be.\n",
    "- **Number of documents to retrieve** - This specifies the number of documents to retrieve. It may seem like more is better, but remember, it's important to keep the signal to noise ratio of your retrieval process high. The more documents you retrieve the more likely it is you'll overwhelm your model.\n",
    "You'll often see us refer to this method as \"vanilla retrieval.\" This is a delicious example of the basic retrieval method which powers many chatbots and question/answer tools. Further, it's commonly referred to as the \"Hello world\" example of doing retrieval.\n",
    "\n",
    "Why is this helpful?\n",
    "- **Simple** - This method has very few moving parts while taking advantage of powerful language models\n",
    "- **Foundational** - This method is the start point for many advanced methods of retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install openai python-dotenv --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PDF Loaders. If unstructured gives you a hard time, try PyPDFLoader\n",
    "from langchain.document_loaders import UnstructuredPDFLoader, OnlinePDFLoader, PyPDFLoader, TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load your data**\n",
    "\n",
    "Next let's load up some data. I've put a few 'loaders' on there which will load data from different locations. Feel free to use the one that suits you. The default one queries one of Paul Graham's essays for a simple example. This process will only stage the loader, not actually load it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = TextLoader(file_path=\"../data/vb.txt\")\n",
    "\n",
    "## Other options for loaders \n",
    "# loader = PyPDFLoader(\"../data/field-guide-to-data-science.pdf\")\n",
    "# loader = UnstructuredPDFLoader(\"../data/field-guide-to-data-science.pdf\")\n",
    "# loader = OnlinePDFLoader(\"https://wolfpaulus.com/wp-content/uploads/2017/05/field-guide-to-data-science.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then let's go ahead and actually load the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then let's actually check out what's been loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have 1 document(s) in your data\n",
      "There are 9160 characters in your sample document\n",
      "Here is a sample: Life is Short\n",
      "\n",
      "January 2016\n",
      "\n",
      "Life is short, as everyone knows. When I was a kid I used to wonder about this. Is life actually short, or are we really complaining about its finiteness? Would we be just\n"
     ]
    }
   ],
   "source": [
    "# Note: If you're using PyPDFLoader then it will split by page for you already\n",
    "print (f'You have {len(data)} document(s) in your data')\n",
    "print (f'There are {len(data[0].page_content)} characters in your sample document')\n",
    "print (f'Here is a sample: {data[0].page_content[:200]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Chunk your data up into smaller documents**\n",
    "\n",
    "While we could pass the entire essay to a model w/ long context, we want to be picky about which information we share with our model. The better signal to noise ratio we have the more likely we are to get the right answer.\n",
    "\n",
    "The first thing we'll do is chunk up our document into smaller pieces. The goal will be to take only a few of those smaller pieces and pass them to the LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll split our data into chunks around 500 characters each with a 50 character overlap. These are relatively small.\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "texts = text_splitter.split_documents(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now you have 27 documents\n"
     ]
    }
   ],
   "source": [
    "# Let's see how many small chunks we have\n",
    "print (f'Now you have {len(texts)} documents')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create embeddings of your documents to get ready for semantic search**\n",
    "\n",
    "Next up we need to prepare for similarity searches. The way we do this is through embedding our documents (getting a vector per document).\n",
    "\n",
    "This will help us compare documents later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain_openai import AzureOpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we'll get our embeddings engine going. You can use whatever embeddings engine you would like. We'll use OpenAI's ada today."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = AzureOpenAIEmbeddings(\n",
    "    azure_endpoint=os.getenv(\"AZURE_OPENAI_EMBEDDING_ENDPOINT\"),\n",
    "    openai_api_key=os.getenv(\"AZURE_OPENAI_EMBEDDING_API_KEY\"),\n",
    "    openai_api_version=os.getenv(\"AZURE_OPENAI_EMBEDDING_API_VERSION\"),\n",
    "    azure_deployment=\"text-embedding-3-small\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I like Chroma because it's local and easy to set up without an account.\n",
    "\n",
    "First we'll pass our texts to Chroma via `.from_documents`, this will 1) embed the documents and get a vector, then 2) add them to the vectorstore for retrieval later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load it into Chroma\n",
    "vectorstore = Chroma.from_documents(texts, embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test it out. I want to see which documents are most closely related to a query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What is great about having kids?\"\n",
    "docs = vectorstore.similarity_search(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can check them out. In theory, the texts which are deemed most similar should hold the answer to our question. But keep in mind that our query just happens to be a question, it could be a random statement or sentence and it would still work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One great thing about having small children is that they make you spend time on things that matter: them. They grab your sleeve as you're staring at your phone and say \"will you play with me?\" And odds are that is in fact the bullshit-minimizing option.\n",
      "\n",
      "It is possible to slow time somewhat. I've gotten better at it. Kids help. When you have small children, there are a lot of moments so perfect that you can't help noticing.\n",
      "\n",
      "It does help too to feel that you've squeezed everything out of some experience. The reason I'm sad about my mother is not just that I miss her but that I think of all the things we could have done that we didn't. My oldest son will be 7 soon. And while I miss the 3 year old version of him, I at least don't have any regrets over what might have been. We had the best time a daddy and a 3 year old ever had.\n",
      "\n",
      "Having kids showed me how to convert a continuous quantity, time, into discrete quantities. You only get 52 weekends with your 2 year old. If Christmas-as-magic lasts from say ages 3 to 10, you only get to watch your child experience it 8 times. And while it's impossible to say what is a lot or a little of a continuous quantity like time, 8 is not a lot of something. If you had a handful of 8 peanuts, or a shelf of 8 books to choose from, the quantity would definitely seem limited, no matter\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Here's an example of the first document that was returned\n",
    "for doc in docs:\n",
    "    print (f\"{doc.page_content}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Query those docs to get your answer back**\n",
    "\n",
    "Great, those are just the docs which should hold our answer. Now we can pass those to a LangChain chain to query the LLM.\n",
    "\n",
    "We could do this manually, but a chain is a convenient helper for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain.chains.question_answering import load_qa_chain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we'll initalize our LLM and our chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = AzureChatOpenAI(\n",
    "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    openai_api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "    openai_api_version=os.getenv(\"OPENAI_API_VERSION\"),\n",
    "    azure_deployment=\"gpt-4\",\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "chain = load_qa_chain(llm, chain_type=\"stuff\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then let's go ask the same question as before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What is great about having kids?\"\n",
    "docs = vectorstore.similarity_search(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_documents': [Document(page_content='One great thing about having small children is that they make you spend time on things that matter: them. They grab your sleeve as you\\'re staring at your phone and say \"will you play with me?\" And odds are that is in fact the bullshit-minimizing option.', metadata={'source': '../data/vb.txt'}),\n",
       "  Document(page_content=\"It is possible to slow time somewhat. I've gotten better at it. Kids help. When you have small children, there are a lot of moments so perfect that you can't help noticing.\", metadata={'source': '../data/vb.txt'}),\n",
       "  Document(page_content=\"It does help too to feel that you've squeezed everything out of some experience. The reason I'm sad about my mother is not just that I miss her but that I think of all the things we could have done that we didn't. My oldest son will be 7 soon. And while I miss the 3 year old version of him, I at least don't have any regrets over what might have been. We had the best time a daddy and a 3 year old ever had.\", metadata={'source': '../data/vb.txt'}),\n",
       "  Document(page_content=\"Having kids showed me how to convert a continuous quantity, time, into discrete quantities. You only get 52 weekends with your 2 year old. If Christmas-as-magic lasts from say ages 3 to 10, you only get to watch your child experience it 8 times. And while it's impossible to say what is a lot or a little of a continuous quantity like time, 8 is not a lot of something. If you had a handful of 8 peanuts, or a shelf of 8 books to choose from, the quantity would definitely seem limited, no matter\", metadata={'source': '../data/vb.txt'})],\n",
       " 'question': 'What is great about having kids?',\n",
       " 'output_text': \"Having kids can be a profound and rewarding experience for many reasons. One great thing about having small children is that they can help you focus on what truly matters in life. They demand your attention and presence, often pulling you away from distractions like your phone or other less important tasks, and encourage you to engage with them and the world around you.\\n\\nChildren also have a way of making you appreciate the present moment. Their sense of wonder and the joy they find in simple things can be contagious, leading you to notice and cherish perfect moments that might otherwise pass you by.\\n\\nMoreover, having children can teach you to value time differently. As a parent, you become acutely aware of the fleeting nature of childhood and the limited number of special occasions you get to share with your children at each stage of their lives. This can motivate you to make the most of the time you have together, creating meaningful experiences and memories that last a lifetime.\\n\\nLastly, the unconditional love and unique bond that often forms between parents and their children is something that many find deeply fulfilling. Watching your children grow, learn, and develop into their own individuals can be one of life's greatest joys.\"}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"input_documents\":docs, \"question\": query})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Awesome! We just went and queried an external data source!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
