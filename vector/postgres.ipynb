{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Storing and querying for embeddings with PostGreSQL and pgvector\n",
    "\n",
    "With the help from the pgvector extension, you can leverage PostgreSQL as a vector database to store and query OpenAI embeddings. OpenAI embeddings are a type of data representation (in the shape of vectors, i.e., lists of numbers) used to measure the similarity of text strings for OpenAIâ€™s models.\n",
    "\n",
    "The notebook perform following tasks:\n",
    "\n",
    "- Load structured data from a json file, create embeddings for content and title with OpenAI, the results are vectors of 1536 dimensions, and will be stored in pgvector\n",
    "- Perform a vectorized search, finding the closest vectors to the query vector\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start with, we need to run pgvector on docker, run the following command in your terminal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd_stdout = ! < /dev/urandom tr -dc 'A-Za-z0-9' | head -c12; echo\n",
    "pg_password = cmd_stdout.n\n",
    "\n",
    "cmd_stdout = ! docker run -d --name pgvector -p 5432:5432 -e POSTGRES_PASSWORD={pg_password} -e POSTGRES_USER=pgadmin -e POSTGRES_DB=pgvector pgvector/pgvector:pg16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q -U openai psycopg2-binary pgvector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load environment variables and create an openai client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from psycopg2 import pool, extras, sql, Error\n",
    "from psycopg2.extras import execute_values\n",
    "from pgvector.psycopg2 import register_vector\n",
    "import os\n",
    "from openai import AzureOpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),  \n",
    "    api_version=os.getenv(\"OPENAI_API_VERSION\"),\n",
    "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to PostgreSQL\n",
    "\n",
    "Connect to our database using the popular psycopg2 python library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn_string = \"host={0} user={1} dbname={2} password={3} sslmode={4}\".format('127.0.0.1', 'pgadmin', 'pgvector', pg_password, 'disable')\n",
    "pg_pool = psycopg2.pool.SimpleConnectionPool(1, 20, conn_string)\n",
    "if (pg_pool):\n",
    "    print(\"Connection pool created successfully\")\n",
    "\n",
    "# Use getconn() to get a connection from the connection pool\n",
    "connection = pg_pool.getconn()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to use pgvector, we need to first create the vector extension as described in this link and shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    with connection.cursor() as cursor:\n",
    "        # Check if the extension already exists\n",
    "        extension_query = \"SELECT * FROM pg_extension WHERE extname = 'vector';\"\n",
    "        cursor.execute(extension_query)\n",
    "        extension_exists = cursor.fetchone()\n",
    "\n",
    "        if not extension_exists:\n",
    "            # Extension does not exist, create it\n",
    "            create_extension_query = \"CREATE EXTENSION vector;\"\n",
    "            cursor.execute(create_extension_query)\n",
    "            connection.commit()\n",
    "        else:\n",
    "            # Extension already exists, pass through\n",
    "            print(\"Extension already exists\")\n",
    "\n",
    "        connection.commit()\n",
    "except (Exception, Error) as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    connection.rollback()   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following we will list the existing extensions for your db. Please make sure ['VECTOR'] IS listed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the SHOW EXTENSIONS query\n",
    "show_extensions_query = \"select extname from pg_extension;\"\n",
    "\n",
    "# Execute the CREATE TABLE query\n",
    "try:\n",
    "    with connection.cursor() as cursor:\n",
    "        cursor.execute(show_extensions_query)\n",
    "        # Fetch and print the results\n",
    "        results = cursor.fetchall()\n",
    "        for row in results:\n",
    "            print(row)        \n",
    "        connection.commit()\n",
    "except (Exception, Error) as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    connection.rollback()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper function to create document embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "\n",
    "def generate_embeddings(text):\n",
    "    '''\n",
    "    Generate embeddings from string of text.\n",
    "    This will be used to vectorize data and user input for interactions with Azure OpenAI.\n",
    "    '''\n",
    "    response = client.embeddings.create(input=text,  model=\"text-embedding-ada-002\")\n",
    "    embeddings =response.model_dump()\n",
    "    time.sleep(0.5) \n",
    "    return embeddings['data'][0]['embedding']\n",
    "\n",
    "def generate_document_embeddings(input_json_path, output_json_path):\n",
    "    # Read the input JSON file\n",
    "    with open(input_json_path, 'r', encoding='utf-8') as file:\n",
    "        input_data = json.load(file)\n",
    "\n",
    "    titles = [item['title'] for item in input_data]\n",
    "    content = [item['content'] for item in input_data]\n",
    "    \n",
    "    # Generate embeddings for titles\n",
    "    title_response = client.embeddings.create(input=titles, model=\"text-embedding-ada-002\")\n",
    "    title_embeddings = [item.embedding for item in title_response.data]\n",
    "    \n",
    "    # Generate embeddings for content\n",
    "    content_response = client.embeddings.create(input=content, model=\"text-embedding-ada-002\")\n",
    "    content_embeddings = [item.embedding for item in content_response.data]\n",
    "\n",
    "    # Assign embeddings to the original data\n",
    "    for i, item in enumerate(input_data):\n",
    "        item['titleVector'] = title_embeddings[i]\n",
    "        item['contentVector'] = content_embeddings[i]\n",
    "\n",
    "    # Ensure the output directory exists\n",
    "    output_directory = os.path.dirname(output_json_path)\n",
    "    if not os.path.exists(output_directory):\n",
    "        os.makedirs(output_directory)\n",
    "    \n",
    "    # Write the modified data to the output JSON file\n",
    "    with open(output_json_path, \"w\") as f:\n",
    "        json.dump(input_data, f)\n",
    "\n",
    "\n",
    "# Generate and load the documents with embeddings from the output file\n",
    "output_path = os.path.join('output', 'docVectors.json')\n",
    "if not os.path.exists(output_path):\n",
    "    generate_document_embeddings(os.path.join('..', 'data', 'text-sample.json'), output_path)\n",
    "    \n",
    "with open(output_path, 'r') as file:  \n",
    "    documents = json.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data and vectors to a table in the database\n",
    "In this section, we will load the data into a pandas dataframe, use select columns, and create vector embedding using azure open ai."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.DataFrame(documents, columns=['id', 'title', 'content', 'category', 'titleVector', 'contentVector'])\n",
    "data_list = [(int(row['id']), row['title'], row['content'], row['category'], np.array(row['titleVector']), np.array(row['contentVector'])) for index, row in df.iterrows()]\n",
    "\n",
    "# Register 'pgvector' type\n",
    "register_vector(connection)\n",
    "\n",
    "# # Drop previous table of same name if one exists\n",
    "\"\"\"\n",
    "drop_table_query = \"DROP TABLE IF EXISTS vs;\"\n",
    "try:\n",
    "    with connection.cursor() as cursor:\n",
    "        cursor.execute(drop_table_query)\n",
    "        print(\"Finished dropping table (if existed)\")\n",
    "        connection.commit()\n",
    "except (Exception, Error) as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    connection.rollback()\n",
    "\"\"\"\n",
    "\n",
    "# Execute the query to check if the table exists\n",
    "table_exists_query = \"SELECT EXISTS (SELECT 1 FROM information_schema.tables WHERE table_name = 'vs');\"\n",
    "try:\n",
    "    with connection.cursor() as cursor:\n",
    "        cursor.execute(table_exists_query)\n",
    "        # Fetch and print the results\n",
    "        exists = cursor.fetchone()[0]       \n",
    "        connection.commit()\n",
    "except (Exception, Error) as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    connection.rollback()\n",
    "    raise\n",
    "\n",
    "if exists:\n",
    "    print(f\"The table vs exists in the database.\")\n",
    "    print(\"You may drop previous table if you want to re-insert data.\")\n",
    "else:\n",
    "    print(f\"The table vs does not exist in the database. Creating it now and inserting data ...\")\n",
    "    # Define the CREATE TABLE query\n",
    "    create_table_query = f\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS vs (\n",
    "        Id INTEGER PRIMARY KEY,\n",
    "        Title TEXT,\n",
    "        Content TEXT,\n",
    "        Category TEXT,\n",
    "        TitleVector VECTOR(1536),\n",
    "        ContentVector VECTOR(1536)\n",
    "    );\n",
    "    \"\"\"\n",
    "\n",
    "    # Execute the CREATE TABLE query\n",
    "    try:\n",
    "        with connection.cursor() as cursor:\n",
    "            cursor.execute(create_table_query)\n",
    "            connection.commit()\n",
    "            print(f\"Table vs created successfully!\")\n",
    "    except (Exception, Error) as e:\n",
    "        print(f\"Error creating table vs: {e}\")\n",
    "        connection.rollback()     \n",
    "\n",
    "    # Batch insert data and embeddings into PostgreSQL database\n",
    "    try:\n",
    "        with connection.cursor() as cursor:\n",
    "            execute_values(cursor, \"INSERT INTO vs (Id, Title, Content, Category, TitleVector, ContentVector) VALUES %s\", data_list)\n",
    "            connection.commit()\n",
    "            print(f\"Data inserted to table vs successfully!\")\n",
    "    except (Exception, Error) as e:\n",
    "        print(f\"Error inserting data to vs: {e}\")\n",
    "        connection.rollback()           \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Asks a Question and retrieves the top K document chunks based on the users' question using the similarity.\n",
    "\n",
    "In this step, the code will convert the user's question to an embedding and then retieve the top K document chunks based on the users' question using the similarity. Please note that other similarity metrics can also be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What is Azure App Service?\"\n",
    "retrieve_k = 3 # for retrieving the top k reviews from the database\n",
    "# Generate embeddings for the question and retrieve the top k document chunks\n",
    "question_embedding = generate_embeddings(question)\n",
    "select_query = f\"SELECT Id, Title, Content, Category, ContentVector <-> %s::vector as distance FROM vs ORDER BY ContentVector <-> %s::vector LIMIT {retrieve_k}\"\n",
    "\n",
    "try:\n",
    "    with connection.cursor() as cursor:\n",
    "        cursor.execute(select_query, (np.array(question_embedding),np.array(question_embedding),))\n",
    "        results = cursor.fetchall()\n",
    "        connection.commit()\n",
    "except (Exception, Error) as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    connection.rollback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
