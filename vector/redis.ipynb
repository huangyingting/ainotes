{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --quiet -U openai redis requests bs4 feedparser numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%docker run -d --name redis-stack-server -p 6379:6379 redis/redis-stack-server:latest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries:  10\n",
      "Create embedding and save for entry  0  of  10\n",
      "Create embedding and save for entry  1  of  10\n",
      "Create embedding and save for entry  2  of  10\n",
      "Create embedding and save for entry  3  of  10\n",
      "Create embedding and save for entry  4  of  10\n",
      "Create embedding and save for entry  5  of  10\n",
      "Create embedding and save for entry  6  of  10\n",
      "Create embedding and save for entry  7  of  10\n",
      "Create embedding and save for entry  8  of  10\n",
      "Create embedding and save for entry  9  of  10\n",
      "Vector upload complete.\n"
     ]
    }
   ],
   "source": [
    "import feedparser\n",
    "import numpy as np\n",
    "from openai import AzureOpenAI\n",
    "import redis\n",
    "from redis.commands.search.field import VectorField, TextField\n",
    "from redis.commands.search.query import Query\n",
    "from redis.commands.search.indexDefinition import IndexDefinition, IndexType\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Redis connection details\n",
    "redis_host = os.getenv('REDIS_HOST')\n",
    "redis_port = os.getenv('REDIS_PORT')\n",
    "redis_password = os.getenv('REDIS_PASSWORD')\n",
    "\n",
    "# Connect to the Redis server\n",
    "conn = redis.Redis(host=os.getenv('REDIS_HOST'), \n",
    "                   port=os.getenv('REDIS_PORT'), \n",
    "                   password=os.getenv('REDIS_PASSWORD'), \n",
    "                   encoding='utf-8', \n",
    "                   decode_responses=True)\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    api_key = os.getenv(\"AZURE_OPENAI_KEY\"),  \n",
    "    api_version=os.getenv(\"OPENAI_API_VERSION\"),\n",
    "    azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    ")\n",
    "\n",
    "SCHEMA = [\n",
    "    TextField(\"url\"),\n",
    "    VectorField(\"embedding\", \"HNSW\", {\"TYPE\": \"FLOAT32\", \"DIM\": 1536, \"DISTANCE_METRIC\": \"COSINE\"}),\n",
    "]\n",
    "\n",
    "# Create the index\n",
    "try:\n",
    "    conn.ft(\"posts\").create_index(fields=SCHEMA, definition=IndexDefinition(prefix=[\"post:\"], index_type=IndexType.HASH))\n",
    "except Exception as e:\n",
    "    print(\"Index already exists\")\n",
    "\n",
    "# URL of the RSS feed to parse\n",
    "url = 'https://devblogs.microsoft.com/landingpage/'\n",
    "\n",
    "# Parse the RSS feed with feedparser\n",
    "feed = feedparser.parse(url)\n",
    "\n",
    "# get number of entries in feed\n",
    "entries = len(feed.entries)\n",
    "print(\"Number of entries: \", entries)\n",
    "\n",
    "p = conn.pipeline(transaction=False)\n",
    "for i, entry in enumerate(feed.entries[:50]):\n",
    "    # report progress\n",
    "    print(\"Create embedding and save for entry \", i, \" of \", entries)\n",
    "    \n",
    "    article = entry.description\n",
    "\n",
    "    embedding = client.embeddings.create(\n",
    "        input=article,\n",
    "        model=\"text-embedding-ada-002\"\n",
    "    )\n",
    "\n",
    "    # print the embedding (length = 1536)\n",
    "    vector = embedding.data[0].embedding\n",
    "\n",
    "    # convert to numpy array\n",
    "    vector = np.array(vector).astype(np.float32).tobytes()\n",
    "\n",
    "    # Create a new hash with the URL and embedding\n",
    "    post_hash = {\n",
    "        \"url\": entry.link,\n",
    "        \"embedding\": vector\n",
    "    }\n",
    "    \n",
    "    # add_document() is deprecated\n",
    "    conn.hset(name=f\"post:{i}\", mapping=post_hash)\n",
    "\n",
    "p.execute()\n",
    "\n",
    "print(\"Vector upload complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to Redis\n",
      "Vectorizing query...\n",
      "Searching for similar posts...\n",
      "Found 5 results:\n",
      "\t0. https://devblogs.microsoft.com/identity/eng-connect-jun-24 (Score: 0.825)\n",
      "\t1. https://devblogs.microsoft.com/visualstudio/automatically-install-visual-studio-security-updates-through-microsoft-update (Score: 0.816)\n",
      "\t2. https://devblogs.microsoft.com/directx/step-forward-for-gaming-on-arm-devices-2024 (Score: 0.81)\n",
      "\t3. https://devblogs.microsoft.com/qsharp/evaluating-cat-qubits-for-fault-tolerant-quantum-computing-using-azure-quantum-resource-estimator (Score: 0.796)\n",
      "\t4. https://devblogs.microsoft.com/ise/empowering-collaboration-with-tech-savvy-customer (Score: 0.785)\n"
     ]
    }
   ],
   "source": [
    "def search_vectors(query_vector, client, top_k=5):\n",
    "    base_query = \"*=>[KNN 5 @embedding $vector AS vector_score]\"\n",
    "    query = Query(base_query).return_fields(\"url\", \"vector_score\").sort_by(\"vector_score\").dialect(2)    \n",
    "\n",
    "    try:\n",
    "        results = client.ft(\"posts\").search(query, query_params={\"vector\": query_vector})\n",
    "    except Exception as e:\n",
    "        print(\"Error calling Redis search: \", e)\n",
    "        return None\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "if conn.ping():\n",
    "    print(\"Connected to Redis\")\n",
    "\n",
    "# Enter a query\n",
    "query = \"Microsoft\"\n",
    "\n",
    "# Vectorize the query using OpenAI's text-embedding-ada-002 model\n",
    "print(\"Vectorizing query...\")\n",
    "embedding = client.embeddings.create(input=query, model=\"text-embedding-ada-002\")\n",
    "query_vector = embedding.data[0].embedding\n",
    "\n",
    "# Convert the vector to a numpy array\n",
    "query_vector = np.array(query_vector).astype(np.float32).tobytes()\n",
    "\n",
    "# Perform the similarity search\n",
    "print(\"Searching for similar posts...\")\n",
    "results = search_vectors(query_vector, conn)\n",
    "\n",
    "if results:\n",
    "    print(f\"Found {results.total} results:\")\n",
    "    for i, post in enumerate(results.docs):\n",
    "        score = 1 - float(post.vector_score)\n",
    "        print(f\"\\t{i}. {post.url} (Score: {round(score ,3) })\")\n",
    "else:\n",
    "    print(\"No results found\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
